{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home App \n",
    "## Part V- Organizing model for App\n",
    "\n",
    "The data for this project comes from Kaggle  [House Sales in King County, USA](https://www.kaggle.com/architdxb/king-countyusa/data). The list of variables is shown below.\n",
    "\n",
    "The variables that we will use are:\n",
    "\n",
    "* **id** : house identification number\n",
    "* **price** : target variable for prediction\n",
    "* **bedrooms** : number of bedrooms in the home\n",
    "* **bathrooms** : number of bathrooms in the home\n",
    "* **sqft_living** : square footage of the home\n",
    "* **sqft_lot** : square footage of the lot\n",
    "* **yr_built** : year the home was built\n",
    "* **yr_renovated** : year the home was renovated\n",
    "* **zipcode** : zip code of the home\n",
    "\n",
    "For Part V of the project, we're just organizing everything in a simple format without any data exploration steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset has 21969 samples with 8 features each.\n"
     ]
    }
   ],
   "source": [
    "# load necessary packages \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from time import time\n",
    "\n",
    "# pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "data_path = \"C:/Users/Yiruru/Documents/launchCode/data/processed_data.csv\"\n",
    "df= pd.read_csv(data_path)\n",
    "# Load and merge the housing data\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Main dataset has {} samples with {} features each.\".format(*df.shape))\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = df\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'year', 'zipcode']\n",
    "price_raw = new_data['price']\n",
    "features_raw = new_data.drop('price', axis = 1)\n",
    "features_raw[numerical] = scaler.fit_transform(new_data[numerical])\n",
    "\n",
    "features = pd.get_dummies(features_raw)\n",
    "price = new_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 15378 samples.\n",
      "Validation set has 3296 samples.\n",
      "Testing set has 3295 samples.\n",
      "Testing set is 15.0%.\n"
     ]
    }
   ],
   "source": [
    "# Train and Test \n",
    "X = new_data.ix[:, :-1]\n",
    "Y = new_data.ix[:, -1]\n",
    "\n",
    "# Import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state = 42)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(x_train.shape[0]))\n",
    "print(\"Validation set has {} samples.\".format(x_val.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(x_test.shape[0]))\n",
    "\n",
    "# confirm % of test set\n",
    "print(\"Testing set is {}%.\".format(round(1.*x_test.shape[0]/features.shape[0]*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3: Characteristics of Training, Validation, and Test Set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>validation Set</th>\n",
       "      <th>Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sample Size</th>\n",
       "      <td>15378</td>\n",
       "      <td>3296</td>\n",
       "      <td>3295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log error</th>\n",
       "      <td>540842.6695</td>\n",
       "      <td>529067.9600</td>\n",
       "      <td>534933.2155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Training Set validation Set     Test Set\n",
       "Sample Size  15378        3296           3295       \n",
       "log error    540842.6695  529067.9600    534933.2155"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data characteristics on the training set\n",
    "n_train = round(len(x_train), 0)\n",
    "n_val = round(len(x_val), 0)\n",
    "n_test = round(len(x_test),1)\n",
    "\n",
    "y_train_mean = y_train.mean()\n",
    "y_val_mean = y_val.mean()\n",
    "y_test_mean = y_test.mean()\n",
    "\n",
    "basic_df = pd.DataFrame([['{:.0f}'.format(n_train), '{:.0f}'.format(n_val), '{:.0f}'.format(n_test)], \n",
    "                         ['{:.4f}'.format(y_train_mean), '{:.4f}'.format(y_val_mean), '{:.4f}'.format(y_test_mean)]], \n",
    "                        index=['Sample Size', 'log error'], \n",
    "                        columns=['Training Set', 'validation Set', 'Test Set'])\n",
    "print('Table 3: Characteristics of Training, Validation, and Test Set')\n",
    "basic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer, precision_score, recall_score, mean_squared_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "scoring_function = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "target = 'price'\n",
    "predictors = new_data.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='rmse', early_stopping_rounds=early_stopping_rounds, verbose_eval= True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['price'],eval_metric='rmse')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "     \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Mean Square error : %.4g\" % metrics.mean_squared_error(dtrain['price'].values, dtrain_predictions))\n",
    "    print(\"r2 Score : %.4g\" % metrics.r2_score(dtrain['price'].values, dtrain_predictions))\n",
    "    return dtrain_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id  bedrooms  bathrooms  sqft_living  sqft_lot  zipcode  year  \\\n",
      "0      3990200065  4         2.50       2050         9143      98166    1992   \n",
      "1      1525069021  3         2.50       2580         214315    98053    1986   \n",
      "2      9553200125  3         1.50       2440         5750      98115    1939   \n",
      "3      3080000030  3         2.50       2230         4000      98144    1954   \n",
      "4      3782760040  3         3.25       2780         4002      98019    2009   \n",
      "5      5152960350  4         2.75       2390         9650      98003    1976   \n",
      "6      3992700585  3         1.75       1880         9360      98125    1941   \n",
      "7      6071700020  3         2.25       1640         8400      98006    1962   \n",
      "8      3902310210  4         2.50       2100         8800      98033    1980   \n",
      "9      4435000705  3         1.00       1350         8700      98188    1942   \n",
      "10     925049278   4         2.00       1490         4054      98115    1926   \n",
      "11     9834200165  4         1.50       1790         4080      98144    1928   \n",
      "12     7853321180  5         2.50       2550         6405      98065    2008   \n",
      "13     2473400290  4         2.50       1870         8190      98058    1977   \n",
      "14     3293700480  4         1.75       2200         8545      98133    1982   \n",
      "15     5104512070  4         3.00       2430         7242      98038    2003   \n",
      "16     9274200316  3         2.50       1680         934       98116    2008   \n",
      "17     1392800035  2         1.00       1240         6400      98126    1938   \n",
      "18     6791100410  3         2.50       1660         15000     98075    1970   \n",
      "19     4139480200  4         3.25       4290         12103     98006    1997   \n",
      "20     2314300200  4         3.00       2580         7299      98058    1998   \n",
      "21     8731730710  3         1.00       1180         9000      98031    1970   \n",
      "22     2193310320  4         2.50       2330         7064      98052    1984   \n",
      "23     3052700610  6         3.50       2820         5400      98117    1958   \n",
      "24     427000065   5         2.50       4340         9108      98118    1979   \n",
      "25     1450900020  3         2.00       1610         8416      98031    1994   \n",
      "26     2473250280  4         2.25       2300         9100      98058    1977   \n",
      "27     6821102367  3         2.50       1570         1452      98199    2007   \n",
      "28     5315100394  3         1.00       1440         13824     98040    1957   \n",
      "29     4217400420  3         1.50       1340         6000      98105    1927   \n",
      "...           ... ..          ...        ...          ...        ...     ...   \n",
      "15348  2770601595  2         1.00       1470         6000      98199    1944   \n",
      "15349  1126059201  5         3.25       4410         35192     98072    1990   \n",
      "15350  1954440060  3         2.50       1900         8744      98074    1987   \n",
      "15351  985001266   3         1.50       2210         11111     98168    1934   \n",
      "15352  8901000543  3         2.50       2590         7237      98125    2004   \n",
      "15353  2491200330  3         2.50       1690         5131      98126    1998   \n",
      "15354  5101405604  1         1.00       900          6380      98125    1947   \n",
      "15355  3885805640  3         1.50       1300         7200      98033    1960   \n",
      "15356  1423069162  4         2.25       2740         88426     98027    1991   \n",
      "15357  8669160270  3         2.50       1550         3402      98002    2009   \n",
      "15358  7334501300  3         1.75       1630         11475     98045    1979   \n",
      "15359  8122100595  2         1.00       940          5040      98126    1926   \n",
      "15360  2487200938  5         3.25       3230         5000      98136    2002   \n",
      "15361  9165100130  3         1.75       1180         4080      98117    1928   \n",
      "15362  2413300240  4         2.25       1990         7350      98003    1978   \n",
      "15363  9273200140  2         2.25       3950         3938      98116    1991   \n",
      "15364  3649100473  3         1.50       1300         12240     98028    1963   \n",
      "15365  6908200650  3         2.50       2330         1987      98107    2004   \n",
      "15366  2545900050  3         1.00       1360         9948      98010    1977   \n",
      "15367  6683000295  3         2.50       2010         14298     98070    1977   \n",
      "15368  2517010230  3         2.50       1800         3980      98042    2006   \n",
      "15369  2024059058  4         2.75       2890         7821      98006    2014   \n",
      "15370  1133000235  6         2.25       3550         11780     98125    1948   \n",
      "15371  2321300351  2         1.00       1510         4032      98199    1935   \n",
      "15372  1924069105  3         1.75       3150         9258      98027    1970   \n",
      "15373  59000445    4         2.75       2240         5400      98116    1940   \n",
      "15374  8669160170  3         2.50       1550         3569      98002    2011   \n",
      "15375  1862000010  4         2.50       3400         35062     98052    1988   \n",
      "15376  108000127   4         3.50       2000         2309      98177    2008   \n",
      "15377  8931100095  2         2.25       2130         5920      98115    1950   \n",
      "\n",
      "           price  \n",
      "0      360000.0   \n",
      "1      400000.0   \n",
      "2      875000.0   \n",
      "3      398750.0   \n",
      "4      402500.0   \n",
      "5      379750.0   \n",
      "6      445500.0   \n",
      "7      515000.0   \n",
      "8      610000.0   \n",
      "9      160000.0   \n",
      "10     607000.0   \n",
      "11     704300.0   \n",
      "12     465000.0   \n",
      "13     285000.0   \n",
      "14     414950.0   \n",
      "15     412000.0   \n",
      "16     558000.0   \n",
      "17     559000.0   \n",
      "18     432000.0   \n",
      "19     1400000.0  \n",
      "20     449500.0   \n",
      "21     215000.0   \n",
      "22     595000.0   \n",
      "23     850000.0   \n",
      "24     537500.0   \n",
      "25     268000.0   \n",
      "26     265000.0   \n",
      "27     547000.0   \n",
      "28     604000.0   \n",
      "29     907000.0   \n",
      "...         ...   \n",
      "15348  415000.0   \n",
      "15349  1270000.0  \n",
      "15350  560000.0   \n",
      "15351  250000.0   \n",
      "15352  620000.0   \n",
      "15353  460000.0   \n",
      "15354  350000.0   \n",
      "15355  625000.0   \n",
      "15356  549000.0   \n",
      "15357  273500.0   \n",
      "15358  308000.0   \n",
      "15359  212700.0   \n",
      "15360  815000.0   \n",
      "15361  450000.0   \n",
      "15362  280000.0   \n",
      "15363  1310000.0  \n",
      "15364  365000.0   \n",
      "15365  732000.0   \n",
      "15366  234950.0   \n",
      "15367  350000.0   \n",
      "15368  286000.0   \n",
      "15369  978000.0   \n",
      "15370  450000.0   \n",
      "15371  575000.0   \n",
      "15372  450000.0   \n",
      "15373  590000.0   \n",
      "15374  259000.0   \n",
      "15375  915000.0   \n",
      "15376  456500.0   \n",
      "15377  779000.0   \n",
      "\n",
      "[15378 rows x 8 columns]\n",
      "r2 Score : 0.7858\n"
     ]
    }
   ],
   "source": [
    "#combine x_train and y_train for model tuning \n",
    "df_train = pd.concat([x_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# gather test set \n",
    "df_test = pd.concat([x_test.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n",
    "test_pred = xgb2.predict(df_test[predictors])\n",
    "df_test['pred'] = test_pred\n",
    "\n",
    "# final model \n",
    "xgb2 = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=406,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'reg:linear',\n",
    " reg_alpha = 100, \n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=100)\n",
    "\n",
    "# data set used for training\n",
    "print(df_train)\n",
    "xgb2.fit(df_train[predictors], df_train['price'],eval_metric='rmse')\n",
    "dtest_predictions = xgb2.predict(df_test[predictors])\n",
    "print(\"r2 Score : %.4g\" % metrics.r2_score(df_test['price'].values, dtest_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
